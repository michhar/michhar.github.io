<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>On using an Adaline Artificial Neuron for Classification - Data Science <3 Machine Learning Blog</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/obsidian.min.css">
        <link href="../extra_css/extra.css" rel="stylesheet">
        <link href="../extra_css/syntax.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-86308542-1', 'auto');
            ga('send', 'pageview');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="..">Data Science <3 Machine Learning Blog</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Posts <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../survive-thrive-ds-career/" class="dropdown-item">Survive and Thrive in Your Data Science Career Meetup Summary</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Archive <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2019</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../learning-from-learning-yolov3/" class="dropdown-item">Lessons from YOLO v3 Implementations in PyTorch</a>
</li>
            
<li>
    <a href="../bilstm-crf-this-is-mind-bending/" class="dropdown-item">Named Entity Recognition using a Bi-LSTM with the Conditional Random Field Algorithm</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2018</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../how-i-built-pytorch-gpu/" class="dropdown-item">Building PyTorch with LibTorch From Source with CUDA Support</a>
</li>
            
<li>
    <a href="../convert-pytorch-onnx/" class="dropdown-item">How to Convert a PyTorch Model to ONNX Format</a>
</li>
            
<li>
    <a href="../convolutional-in-layers-and-sequences/" class="dropdown-item">Convolutional Neural Networks in Four Deep Learning Frameworks by Example</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2017</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../cntk-has-feelings-too/" class="dropdown-item">The Cognitive Toolkit (CNTK) Understands How You Feel</a>
</li>
            
<li>
    <a href="../masks_to_polygons_and_back/" class="dropdown-item">Shapely Shapes and OpenCV Visions</a>
</li>
            
<li>
    <a href="../my-new-static-site-generator-hobby/" class="dropdown-item">Overlaying a Website ontop of a GitHub Repository</a>
</li>
            
<li>
    <a href="../two-cents-on-python-package-structure/" class="dropdown-item">Wading In a Tide Pool of Choices, How to Write a Package in Python?</a>
</li>
            
<li>
    <a href="../ocrbot-gets-attached/" class="dropdown-item">OCRBot Gets Attached</a>
</li>
            
<li>
    <a href="../jupyter-and-beaker-make-a-case/" class="dropdown-item">The Notebook Superhero -- Is It Always a Contest?</a>
</li>
            
<li>
    <a href="../javascript-and-python-have-a-party/" class="dropdown-item">Javascript and Python Meet through Magic and IPython</a>
</li>
            
<li>
    <a href="../confusion-matrix-code-revealed/" class="dropdown-item">A Simple, Presentable Confusion Matrix with K-means Data</a>
</li>
            
<li>
    <a href="../a-python-flask-webapp-gets-smart/" class="dropdown-item">Creating a Smart Python Flask Web App using Azure Machine Learning</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2016</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../ocrbot-makes-a-connection/" class="dropdown-item">OCRBot Makes a Connection to the Cloud</a>
</li>
            
<li>
    <a href="../how-to-bot-on-mac/" class="dropdown-item">Building an OCR Chat Bot with the Microsoft Bot Framework on my Mac</a>
</li>
            
<li>
    <a href="../teaching-notes-post/" class="dropdown-item">Tips I have Learned by Being a Trainer for a Year</a>
</li>
            
<li>
    <a href="../notebooks1-post/" class="dropdown-item">Python for Data Science Goes Into the Wild</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a href="https://github.com/michhar/michhar.github.io/edit/master/docs/single-artifical-neuron-for-nonlinear-separable-data.markdown" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            
            
            
            
            
            
            
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><strong>tl:dr</strong>:  Getting a simple, predictive framework distinguishing two types of leukemia based on biological markers from a single-layer neural network was not the intent of this exercise. It is, however, indicative of the power of a single artificial neuron and thoughtful feature reduction.</p>
<p><strong>Posted:</strong>  2017-07-19</p>
<h3 id="introduction">Introduction</h3>
<p>The intent of this post originally was to show the inner workings and limitations of a single artificial neuron using some moderately complex, noisy data; a challenge of sorts - "is this noisy data linearly separable with a single artificial neuron and if not, why is that?".  </p>
<p>However, I found with some data and algorithm exploration, that I could distinguish between two types of leukemia â€” a naive approach and not really biologically significant, but an interesting outcome nonetheless.  So, even though this post is about the data science, it also touches on a potential method to use in the real world.</p>
<p>In this post, you'll find information on the use of PCA for data reduction/feature engineering, scaling and normalization for preprocessing, the Adaline algorithm (artificial neuron), different activation functions, among other topics and concepts.</p>
<ul>
<li><a href="#what-is-an-adaline-artificial-neuron">What is an Adaline artificial neuron</a></li>
<li><a href="#adaline-with-a-sigmoid-activation-function">Adaline with a sigmoid activation function</a></li>
<li><a href="#choosing-an-activation-function">Choosing an activation function</a></li>
<li><a href="#the-noisy-data">The noisy data</a></li>
<li><a href="#3d-to-run-through-network-and-2d-to-gain-insights">3D to run through network and 2D to gain insights</a></li>
<li><a href="#conclusion-from-my-experiment">Conclusion from my experiment</a></li>
<li><a href="#credits-and-further-reading">Credits and further reading</a></li>
</ul>
<h3 id="what-is-an-adaline-artificial-neuron">What is an Adaline artificial neuron</h3>
<p>The ADAptive LInear NEuron (Adaline) algorithm is very similar to a Perceptron (simplest of the artificial neurons) except that in the Perceptron the weights are updated based on a unit step activation function output (see figure below) whereas Adaline uses a linear activation function to update it's weights giving it a more robust result (that even converges with samples that are not completely separable by a linear hyperplane, unlike the Perceptron).  In Adaline a <em>quantizer</em> after the activation function, is used to then predict class labels.</p>
<p>Beyond the linear activation function and the <em>quantizer</em>, we see the use of a <em>cost function</em>, or <em>objective function</em>, to update the weights.  In this case we want to minimize this function with an optimization method.  The optimization of the <em>cost function</em> happens with yet another function aptly and simply named an <em>optimization function</em>.  In this case our optimization function is <em>stochastic gradient decent</em>, which one can of as "climbing down a hill" (using part of the data to calculate, shuffled as well) to get to the minima of the cost function's convex curve (as it updates weights iteratively from a shuffled dataset).</p>
<p>A really great discussion from which much of this information was adapted can be found in Sebastian Raschka's <em>Python Machine Learning</em> book (link <a href="https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning">here</a>) and excellent blog post on this topic <a href="http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html">here</a> on the single-layer neurons.</p>
<h3 id="adaline-with-a-sigmoid-activation-function">Adaline with a sigmoid activation function</h3>
<p>I grabbed Raschka's ADAptive LInear NEuron (Adaline) classifier open-source code <a href="https://github.com/PacktPublishing/Python-Machine-Learning/blob/master/3547_02_Code.ipynb">here</a> (the AdalineSGD class) and updated the activation function to logistic sigmoid from a linear function.</p>
<p>Note, with the Adaline (versus the Perceptron) we use a continuous number rather than the binary class label, to compute the model error and update the weights.  Then to predict a class label, another function is used called a <em>quantizer</em>.  Also, the weights are updated in a more sophisticated manner.</p>
<h3 id="choosing-an-activation-function">Choosing an activation function</h3>
<p><img alt="" src="/img/single_layer_neuron/singleneuron_activation.png" /></p>
<p>In code, given this "net input" function:</p>
<div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">net_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate net input&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<p>I update the activation function from linear as in:   </p>
<div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute linear activation&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div>
<p>To a logistic sigmoidal function:</p>
<div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute sigmoidal activation</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A 1d array of length n_samples</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">v</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">x</span><span class="p">)))</span>
</code></pre></div>
<p>Full code <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/machine_learning/leukemia_notebook.ipynb">here</a> and <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/machine_learning/adaline_sgd.py">here</a>.</p>
<p><strong>We still get linear classification boundaries</strong></p>
<p>These single-neuron classifiers can only result in linear decision boundaries, even if using a non-linear activation, because it's still using a single threshold value, <code>z</code> as in diagram above, to decide whether a data point is classified as 1 or -1.</p>
<h3 id="the-noisy-data">The noisy data</h3>
<p>The data was downloaded from the Machine Learning Data Set Repository <a href="https://mldata.org">mldata.org</a> using a convenience function from <code>scikit-learn</code>.  </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.datasets.mldata</span> <span class="kn">import</span> <span class="n">fetch_mldata</span>

<span class="c1"># Fetch a small leukemia dataset from mldata.org</span>
<span class="c1">#   http://mldata.org/repository/data/viewslug/leukemia-all-vs-aml/</span>
<span class="n">test_data_home</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
<span class="n">leuk</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s1">&#39;leukemia&#39;</span><span class="p">,</span> <span class="n">transpose_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">data_home</span><span class="o">=</span><span class="n">test_data_home</span><span class="p">)</span>
</code></pre></div>
<p>The data is a small, but wide acute lymphocytic leukemia (ALL) vs. acute myelogenous leukemia (AML) dataset.  It has approximately 7000 biological markers (our features), vs. 72 samples (our data points).</p>
<p>Given the noisy nature of the data and possible skewedness, it was standardized and normalized with convenience functions from <code>scikit-learn</code>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span><span class="p">,</span> <span class="n">Normalizer</span>

<span class="c1"># Fit the scalar to the training dataset for </span>
<span class="c1">#   zero mean and unit variance of features.</span>
<span class="c1">#   Using a robust scaler which is more resistent to outliers.</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Apply the transform</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Apply the same transform to the test dataset </span>
<span class="c1">#   (simulating what happens when we get new data)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Normalizing data as well to scale samples to unit norm</span>
<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div>
<p>Full code <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/machine_learning/leukemia_notebook.ipynb">here</a> and <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/machine_learning/adaline_sgd.py">here</a>.</p>
<p>I tried just one feature reduction with PCA to reduce all 7129 dimensions to 2D at first.  However, I could not separate out the ALL samples from AML - this wasn't necessarily important to my post on Adaline neurons I was writing, but I decided to try something I'd read about recently for kicks.  In fact the idea sprung from a comment in a Python script where a perceptron was used to create non-linear separation of data for a plot (from <a href="https://github.com/daniel-e/pymltools/blob/master/plot_scripts/plot_perceptron_nonlin.py">this</a> script on Github).  The comment went:</p>
<div class="highlight"><pre><span></span><code># map the data into a space with one addition dimension so that
# it becomes linearly separable
</code></pre></div>
<p>So, I gave it a shot.</p>
<h3 id="3d-to-run-through-network-and-2d-to-gain-insights">3D to run through network and 2D to gain insights</h3>
<p>My next step was to try feeding the neural network the data in 3D space (the 3 features or components from the first PCA reduction).</p>
<p>I then reduced the 3D data to 2D, mainly to visualize it.  A hyperplane was drawn (blank dashed line) to represent the decision boundary.  The surface in the diagram below is representative of a sigmoidal output along the direction of the weight vector.</p>
<p><img alt="" src="/img/single_layer_neuron/linearly_sep_leukemia.png" /></p>
<p>Full code <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/machine_learning/leukemia_notebook.ipynb">here</a> and <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/machine_learning/adaline_sgd.py">here</a>.</p>
<p>Note, the stochastic part of the single-neuron optimizer, stochastic gradient decent, causes some variation in the results if run again.  It might be a good idea to do a batch version of the Adaline neuron.  Another note is that one does not necessarily have to use a logistic sigmoidal activation function; it was just used here as an experiment and to prove to myself I'd always get a linear decision boundary.</p>
<h3 id="conclusion-from-my-experiment">Conclusion from my experiment</h3>
<p>I was surprised and impressed that I got a linearly separable result!  Albeit, that was not the intent of this exercise, but indicative of the power of a single neuron and thoughtful feature reduction.  It makes me wonder what a small neural network could do!</p>
<h3 id="credits-and-further-reading">Credits and further reading</h3>
<ol>
<li>Sebastian Raschka's <em>Python Machine Learning</em> <a href="https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning">book</a></li>
<li>The open-source notebooks with code accompanying the <em>Python Machine Learning</em> book <a href="https://github.com/PacktPublishing/Python-Machine-Learning">here</a> and related code <a href="https://github.com/rasbt/mlxtend/tree/master/mlxtend/classifier">here</a></li>
<li>Raschka's blog <a href="http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html">post</a> on <em>Single-Layer Neural Networks and Gradient Descent</em></li>
<li><code>Scikit-learn</code>'s preprocessing data module <a href="http://scikit-learn.org/stable/modules/preprocessing.html">link</a> for scaling features and samples</li>
</ol></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/0.0.1/prism.min.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
