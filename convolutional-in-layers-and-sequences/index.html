<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Convolutional Neural Networks in Four Deep Learning Frameworks by Example - Data Science <3 Machine Learning</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/obsidian.min.css">
        <link href="../extra_css/extra.css" rel="stylesheet">
        <link href="../extra_css/syntax.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-86308542-1', 'auto');
            ga('send', 'pageview');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
            <div class="container">
                <a class="navbar-brand" href="..">Data Science <3 Machine Learning</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Posts <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../2023-07-poetry-with-conda/" class="dropdown-item">How to Use Poetry with Conda for Package Management on a Specific Python Version</a>
</li>
                                    
<li>
    <a href="../survive-thrive-ds-career/" class="dropdown-item">Survive and Thrive in Your Data Science Career Meetup Summary</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Archive <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2019</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../learning-from-learning-yolov3/" class="dropdown-item">Lessons from YOLO v3 Implementations in PyTorch</a>
</li>
            
<li>
    <a href="../bilstm-crf-this-is-mind-bending/" class="dropdown-item">Named Entity Recognition using a Bi-LSTM with the Conditional Random Field Algorithm</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2018</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../how-i-built-pytorch-gpu/" class="dropdown-item">Building PyTorch with LibTorch From Source with CUDA Support</a>
</li>
            
<li>
    <a href="../convert-pytorch-onnx/" class="dropdown-item">How to Convert a PyTorch Model to ONNX Format</a>
</li>
            
<li>
    <a href="./" class="dropdown-item active">Convolutional Neural Networks in Four Deep Learning Frameworks by Example</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2017</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../cntk-has-feelings-too/" class="dropdown-item">The Cognitive Toolkit (CNTK) Understands How You Feel</a>
</li>
            
<li>
    <a href="../masks_to_polygons_and_back/" class="dropdown-item">Shapely Shapes and OpenCV Visions</a>
</li>
            
<li>
    <a href="../my-new-static-site-generator-hobby/" class="dropdown-item">Overlaying a Website ontop of a GitHub Repository</a>
</li>
            
<li>
    <a href="../two-cents-on-python-package-structure/" class="dropdown-item">Wading In a Tide Pool of Choices, How to Write a Package in Python?</a>
</li>
            
<li>
    <a href="../ocrbot-gets-attached/" class="dropdown-item">OCRBot Gets Attached</a>
</li>
            
<li>
    <a href="../jupyter-and-beaker-make-a-case/" class="dropdown-item">The Notebook Superhero -- Is It Always a Contest?</a>
</li>
            
<li>
    <a href="../javascript-and-python-have-a-party/" class="dropdown-item">Javascript and Python Meet through Magic and IPython</a>
</li>
            
<li>
    <a href="../confusion-matrix-code-revealed/" class="dropdown-item">A Simple, Presentable Confusion Matrix with K-means Data</a>
</li>
            
<li>
    <a href="../a-python-flask-webapp-gets-smart/" class="dropdown-item">Creating a Smart Python Flask Web App using Azure Machine Learning</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">2016</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../ocrbot-makes-a-connection/" class="dropdown-item">OCRBot Makes a Connection to the Cloud</a>
</li>
            
<li>
    <a href="../how-to-bot-on-mac/" class="dropdown-item">Building an OCR Chat Bot with the Microsoft Bot Framework on my Mac</a>
</li>
            
<li>
    <a href="../teaching-notes-post/" class="dropdown-item">Tips I have Learned by Being a Trainer for a Year</a>
</li>
            
<li>
    <a href="../notebooks1-post/" class="dropdown-item">Python for Data Science Goes Into the Wild</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../convert-pytorch-onnx/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../cntk-has-feelings-too/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/michhar/michhar.github.io/edit/master/docs/convolutional-in-layers-and-sequences.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="2"><a href="#introduction" class="nav-link">Introduction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#the-frameworks" class="nav-link">The Frameworks</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#conclusion" class="nav-link">Conclusion</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#references" class="nav-link">References</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#appendix" class="nav-link">Appendix</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><strong>tl;dr</strong>:  No secret: ConvNets are still complex even when you compare across APIs that sound similar for four deep learning frameworks.  Here, you'll find an attempt to compare simple ConvNets in these frameworks.  Also, included is a little ConvNet conceptual breakdown.  Lots of reference code.</p>
<p><strong>Posted:</strong>  2018-05-13</p>
<p><img alt="" src="../img/backprop/IMG_4473.jpg" /></p>
<h2 id="introduction">Introduction</h2>
<p>I've found recently that the Sequential classes and Layer/Layers modules are names used across Keras, PyTorch, TensorFlow and CNTK - making it a little confusing to switch from one framework to another.  I was also curious how easy it would be to use these modules/APIs in each framework to define the same Convolutional neural network (<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">ConvNet</a>).</p>
<p>Let's get through some terminology, first.  You can skip to the <a href="#keras">Code</a> if you are already familiar with ConvNets on images.  Note, the code originates from projects working with MNIST handwritten digits dataset.</p>
<p>The neural network architecture used in this post is as follows.</p>
<ol>
<li>Convolutional layer</li>
<li>Max pooling layer</li>
<li>Convolutional layer</li>
<li>Max pooling layer</li>
<li>Fully connected or dense layer with 10 outputs and softmax activation (to get probabilities)</li>
</ol>
<p>A convolutional layer creates a feature map (using a <em>filter</em> or <em>kernel</em>, which I like to refer to as a "flashlight", shinning on the image and stepping through with a sliding window of 1 unit, that's a <em>stride</em> of 1, by the way).  A good reference for this is in the CNTK <a href="https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html#Convolution-Layer">Tutorial</a>.</p>
<p><img alt="Convolutional layer" src="https://image.slidesharecdn.com/convnets-151015164458-lva1-app6891/95/deep-learning-convolutional-neural-networks-58-638.jpg?cb=1449100605" />
<a href="https://www.slideshare.net/perone/deep-learning-convolutional-neural-networks">Source</a></p>
<p>A pooling layer is a way to subsample an input feature map, or output from the convolutional layer that has already extracted salient features from an image in our case.</p>
<p><img alt="Pooling" src="https://image.slidesharecdn.com/convnets-151015164458-lva1-app6891/95/deep-learning-convolutional-neural-networks-61-638.jpg?cb=1449100605" />
<a href="https://www.slideshare.net/perone/deep-learning-convolutional-neural-networks">Source</a></p>
<p>A fully connected layer is defined such that every input unit is connected to every output unit much like the <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multilayer perceptron</a>.</p>
<p><img alt="Dense layer" src="https://image.slidesharecdn.com/layersintensorflow-170621125437/95/networks-are-like-onions-practical-deep-learning-with-tensorflow-21-638.jpg?cb=1498049767" />
<a href="https://www.slideshare.net/barbarafusinska/networks-are-like-onions-practical-deep-learning-with-tensorflow">Source</a></p>
<p>Not represented in the code below, but important nonetheless, is dropout.  Dropout removes a percentage of the neuron connections - helping to prevent overfitting by reducing the feature space for convolutional and, especially, dense layers.</p>
<p><img alt="Dropout" src="https://image.slidesharecdn.com/convnets-151015164458-lva1-app6891/95/deep-learning-convolutional-neural-networks-68-638.jpg?cb=1449100605" />
<a href="https://www.slideshare.net/perone/deep-learning-convolutional-neural-networks">Source</a></p>
<p>Remember, the power of a convolutional layer is that we don't have to do much upfront raw image processing.  The layer(s) will subsequently find the most salient features for us.</p>
<p>In this post you will find ConvNets defined for four frameworks with adaptations to create easier comparisons (please leave comments as needed).  The full example code can be found as a Jupyter notebook - <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/multi_framework/ConvNet_Comparisons.ipynb">Ref</a>.</p>
<h2 id="the-frameworks">The Frameworks</h2>
<h3 id="keras">Keras</h3>
<p>Below is a ConvNet defined with the <code>Sequential</code> model in Keras (<a href="https://keras.io/getting-started/sequential-model-guide/">Ref</a>).  This is a snippet with only the model definition parts - see the <a href="#references">References</a> for the full code example.</p>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Adapted from:</span>
<span class="sd">https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                 <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                 <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                 <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                 <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">sgd</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> 
              <span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</code></pre></div>
<p>What you don't see is:</p>
<ul>
<li>Fit/train (<code>model.fit()</code>)</li>
<li>Evaluate with given metric (<code>model.evaluate()</code>)</li>
<li>To add dropout after the <code>Convolution2D()</code> layer (or after the fully connected in any of these examples) a dropout function will be used, e.g., <code>Dropout(0.5)</code></li>
<li>Sometimes another fully connected (dense) layer with, say, ReLU activation, is added right before the final fully connected layer.</li>
</ul>
<h3 id="pytorch">PyTorch</h3>
<p>Below is a ConvNet defined with the <code>Sequential</code> container in PyTorch (<a href="https://pytorch.org/docs/master/nn.html?highlight=sequential#torch.nn.Sequential">Ref</a>).  This is a snippet with only the model definition parts - see the <a href="#references">References</a> for the full code example.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">ConvNetPyTorch</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adapted from:</span>
<span class="sd">    https://github.com/rasbt/deep-learning-book/blob/master/code/model_zoo/pytorch_ipynb/convnet.ipynb</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvNetPyTorch</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># 28x28x1 =&gt; 28x28x32</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                      <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># (1(28-1) - 28 + 3) / 2 = 1</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="c1"># 28x28x32 =&gt; 14x14x32</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                         <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                         <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="c1"># (2(14-1) - 28 + 2) = 0    </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># 14x14x32 =&gt; 14x14x64</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                      <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># (1(14-1) - 14 + 3) / 2 = 1   </span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="c1"># 14x14x64 =&gt; 7x7x64</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                         <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                         <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="c1"># (2(7-1) - 14 + 2) = 0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">64</span><span class="p">))</span>
        <span class="n">probas</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">probas</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConvNetPyTorch</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<p>What you don't see is:</p>
<ul>
<li>Fit/train (<code>model.train()</code>)</li>
<li>Evaluate with given metric (<code>model.eval()</code>)</li>
<li>To add dropout after the <code>nn.ReLU()</code> layer (or even after the fully connected in any of these examples) a dropout function will be used, e.g. <code>nn.Dropout(0.5)</code></li>
<li>Sometimes another fully connected (dense) layer with, say, ReLU activation, is added right before the final fully connected layer.</li>
</ul>
<h3 id="tensorflow">Tensorflow</h3>
<p>Below is a ConvNet defined with the <code>Layers</code> library and Estimators API in TensorFlow (<a href="https://www.tensorflow.org/programmers_guide/estimators">Ref</a>).  This is a snippet with only the model definition parts - see the <a href="#references">References</a> for the full code example.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Create the neural network</span>
<span class="k">def</span> <span class="nf">convNetTensorFlow</span><span class="p">(</span><span class="n">x_dict</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">reuse</span><span class="p">,</span> <span class="n">is_training</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adapted from:</span>
<span class="sd">    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Define a scope for reusing the variables</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;ConvNet&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">):</span>
        <span class="c1"># TF Estimator input is a dict, in case of multiple inputs</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x_dict</span><span class="p">[</span><span class="s1">&#39;images&#39;</span><span class="p">]</span>

        <span class="c1"># MNIST data input is a 1-D vector of 784 features (28*28 pixels)</span>
        <span class="c1"># Reshape to match picture format [Height x Width x Channel]</span>
        <span class="c1"># Tensor input become 4-D: [Batch Size, Height, Width, Channel]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Convolution Layer with 32 filters and a kernel size of 5</span>
        <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="c1"># Max Pooling (down-sampling) with strides of 2 and kernel size of 2</span>
        <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">max_pooling2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Convolution Layer with 64 filters and a kernel size of 3</span>
        <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="c1"># Max Pooling (down-sampling) with strides of 2 and kernel size of 2</span>
        <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">max_pooling2d</span><span class="p">(</span><span class="n">conv2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Flatten the data to a 1-D vector for the fully connected layer</span>
        <span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>

        <span class="c1"># Output layer, class prediction</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">fc1</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">logits</span>

<span class="sd">&quot;&quot;&quot;...[snipped for brevity]&quot;&quot;&quot;</span>

<span class="c1"># Build the Estimator</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">Estimator</span><span class="p">(</span><span class="n">model_fn</span><span class="p">)</span>
</code></pre></div>
<p>What you don't see is:</p>
<ul>
<li>Fit/train (<code>model.train()</code>)</li>
<li>Evaluate with given metric (<code>model.evaluate()</code>)</li>
<li>To add dropout after the <code>tf.layers.conv2d()</code> layer (or even after the fully connected in any of these examples) a dropout function will be used, e.g. <code>tf.layers.dropout(inputs=net_layer, rate=0.5, training=is_training)</code></li>
<li>Sometimes another fully connected (dense) layer with, say, ReLU activation, is added right before the final fully connected layer.</li>
</ul>
<p>For more see tensorflow in the <a href="#references">References</a> below.</p>
<h3 id="cognitive-toolkit-cntk">Cognitive Toolkit (CNTK)</h3>
<p>Below is a ConvNet defined with the <code>Layer</code> API in CNTK (<a href="https://www.tensorflow.org/programmers_guide/estimators">Ref</a>).  This is a snippet with only the model definition parts - see the <a href="#references">References</a> for the full code example (Note:  as of this writing CNTK is Windows or Linux only)</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">cntk</span> <span class="k">as</span> <span class="nn">C</span>

<span class="k">def</span> <span class="nf">convNetCNTK</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">num_output_classes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">default_options</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">glorot_uniform</span><span class="p">(),</span> <span class="n">activation</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">relu</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">For</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="p">[</span>
                <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Convolution</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">pad</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
                <span class="p">]),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">out_dims</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="p">])</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</code></pre></div>
<p>What you don't see is:</p>
<ul>
<li>Fit/train (<code>trainer = C.Trainer()</code> and <code>trainer.train_minibatch()</code>)</li>
<li>Evaluate with given metric (<code>out = C.softmax()</code> and <code>out.eval()</code>)</li>
<li>To add dropout after the <code>C.layers.Convolution()</code> layer (or even after the fully connected in any of these examples) a dropout function will be used, e.g. <code>C.layers.Dropout(0.5)</code>.</li>
<li>Sometimes another fully connected (dense) layer with, say, ReLU activation, is added right before the final fully connected layer.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>No real conclusion except to say these frameworks do pretty much the same sorts of things and all have different API layers, high-level to low-level.  I did find Keras to be the easiest and just as fast as TensorFlow - albeit with a lot abstracted away, which is generally good if one needs a quick jumping off point. The benchmarks are not official in full code sample notebook.</p>
<p>The full code samples are in this Jupyter <a href="https://github.com/michhar/python-jupyter-notebooks/blob/master/multi_framework/ConvNet_Comparisons.ipynb">Notebook</a>.  Certainly some room for improvement in code and benchmarking so if you have any ideas, please leave a comment.</p>
<h2 id="references">References</h2>
<p>Samples adapted in this post:</p>
<ol>
<li>Keras code sample with <code>Sequential</code> model <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">Ref</a></li>
<li>PyTorch code sample with <code>Sequential</code> container <a href="https://github.com/rasbt/deep-learning-book/blob/master/code/model_zoo/pytorch_ipynb/convnet.ipynb">Ref</a></li>
<li>TensorFlow code sample with <code>Layers</code> and <code>Estimators</code> APIs <a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py">Ref</a> and ConvNets Tutorial at this <a href="https://www.tensorflow.org/tutorials/deep_cnn">Doc</a></li>
<li>CNTK code sample with <code>Layer</code> API <a href="https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html">Doc</a></li>
</ol>
<p>A great book from which I took some of the concepts written in this post:  <a href="https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning-second-edition">Book</a> and <a href="">Code</a></p>
<p>Even more nice code samples:</p>
<ul>
<li>Kaggle Keras code sample:  <a href="https://www.kaggle.com/tonypoe/keras-cnn-example?scriptVersionId=589403">https://www.kaggle.com/tonypoe/keras-cnn-example?scriptVersionId=589403</a></li>
<li>Keras example:  <a href="http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/">http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/</a></li>
<li>PyTorch example: <a href="https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/convolutional_neural_network/main.py">https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/convolutional_neural_network/main.py</a></li>
<li>CNTK example:  <a href="https://cntk.ai/pythondocs/CNTK_201B_CIFAR-10_ImageHandsOn.html">https://cntk.ai/pythondocs/CNTK_201B_CIFAR-10_ImageHandsOn.html</a> </li>
<li>TensorFlow Estimators example:  <a href="https://jhui.github.io/2017/03/14/TensorFlow-Estimator/">https://jhui.github.io/2017/03/14/TensorFlow-Estimator/</a></li>
</ul>
<p>Thanks for reading.</p>
<h2 id="appendix">Appendix</h2>
<p>Nice explanation of tensor layouts (PyTorch vs. TensorFlow) in a PyTorch forum post by Mamy Ratsimbazafy (<a href="https://discuss.pytorch.org/t/tensorflow-vs-pytorch-convnet-benchmark/8738/3">Post</a>):</p>
<div class="highlight"><pre><span></span><code>Furthermore there might be a difference due to the Tensor layouts:

PyTorch use NCHW and Tensorflow uses NHWC, NCHW was the first layout supported by 
CuDNN but presents a big challenge for optimization (due to access patterns in 
convolutions, memory coalescing and such …).
NHWC is easier to optimize for convolutions but suffer in linear layers iirc 
because you have to physically transpose/permute the dimensions.

Furthermore, due to it’s dynamic nature, PyTorch allocate new memory at 
each new batch while Tensorflow can just reuse previous memory locations 
since size is known in advance.

Memory is THE bottleneck in Deep Learning not CPU, the big challenge is how 
to feed data fast enough to the CPU and GPU to get the maximum GFLOPS throughput.
</code></pre></div>
<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */

    var disqus_config = function () {
        this.page.url = 'https://michhar.github.io/convolutional-in-layers-and-sequences/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'happycat1'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };

    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');

        s.src = 'https://michhar.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/0.0.1/prism.min.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
